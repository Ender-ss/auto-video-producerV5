"""
üéØ Premise Generation Routes
Rotas para gera√ß√£o de premissas de v√≠deos
"""

from flask import Blueprint, request, jsonify
import requests
import json
import os
from services.title_generator import TitleGenerator

premise_bp = Blueprint('premise', __name__)

@premise_bp.route('/generate', methods=['POST'])
def generate_premises():
    """Gerar premissas baseadas nos t√≠tulos fornecidos"""
    try:
        data = request.get_json()
        titles = data.get('titles', [])
        prompt = data.get('prompt', '')
        ai_provider = data.get('ai_provider', 'auto')
        openrouter_model = data.get('openrouter_model', 'auto')
        api_keys = data.get('api_keys', {})

        if not titles:
            return jsonify({
                'success': False,
                'error': 'Nenhum t√≠tulo fornecido'
            }), 400

        # Inicializar o gerador de t√≠tulos (que tamb√©m pode gerar premissas)
        title_generator = TitleGenerator()
        
        # Configurar APIs baseado no provider
        if ai_provider == 'openai' or ai_provider == 'auto':
            if api_keys.get('openai'):
                title_generator.configure_openai(api_keys['openai'])
        
        if ai_provider == 'gemini' or ai_provider == 'auto':
            gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
            if gemini_key:
                title_generator.configure_gemini(gemini_key)
        
        if ai_provider == 'openrouter' or ai_provider == 'auto':
            if api_keys.get('openrouter'):
                title_generator.configure_openrouter(api_keys['openrouter'])

        # Gerar premissas usando o provider especificado
        premises = []
        
        if ai_provider == 'auto':
            # Tentar em ordem de prioridade
            providers = ['openrouter', 'gemini', 'openai']
            success = False
            
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        premises = generate_premises_openrouter(titles, prompt, openrouter_model, api_keys['openrouter'])
                        success = True
                        break
                    elif provider == 'gemini' and (api_keys.get('gemini') or api_keys.get('gemini_1')):
                        premises = generate_premises_gemini(titles, prompt, title_generator)
                        success = True
                        break
                    elif provider == 'openai' and api_keys.get('openai'):
                        premises = generate_premises_openai(titles, prompt, title_generator)
                        success = True
                        break
                except Exception as e:
                    print(f"‚ùå Erro com {provider}: {e}")
                    continue
            
            if not success:
                return jsonify({
                    'success': False,
                    'error': 'Nenhuma IA dispon√≠vel conseguiu gerar premissas'
                }), 500
                
        elif ai_provider == 'openrouter':
            if not api_keys.get('openrouter'):
                return jsonify({
                    'success': False,
                    'error': 'Chave da API OpenRouter n√£o configurada'
                }), 400
            premises = generate_premises_openrouter(titles, prompt, openrouter_model, api_keys['openrouter'])
            
        elif ai_provider == 'gemini':
            gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
            if not gemini_key:
                return jsonify({
                    'success': False,
                    'error': 'Chave da API Gemini n√£o configurada'
                }), 400
            premises = generate_premises_gemini(titles, prompt, title_generator)
            
        elif ai_provider == 'openai':
            if not api_keys.get('openai'):
                return jsonify({
                    'success': False,
                    'error': 'Chave da API OpenAI n√£o configurada'
                }), 400
            premises = generate_premises_openai(titles, prompt, title_generator)

        print(f"üîç DEBUG: Premissas geradas: {len(premises)}")
        for i, premise in enumerate(premises):
            print(f"üîç DEBUG: Premissa {i+1}: t√≠tulo='{premise.get('title', 'N/A')}', premissa_len={len(premise.get('premise', ''))}")

        return jsonify({
            'success': True,
            'premises': premises,
            'provider_used': ai_provider,
            'count': len(premises)
        })

    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o de premissas: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def generate_premises_openrouter(titles, prompt, model, api_key):
    """Gerar premissas usando OpenRouter"""
    try:
        # Mapear modelo autom√°tico para o melhor dispon√≠vel
        if model == 'auto':
            model = 'anthropic/claude-3.5-sonnet'
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:5173',
            'X-Title': 'Auto Video Producer'
        }
        
        response = requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers,
            json={
                'model': model,
                'messages': [
                    {
                        'role': 'system',
                        'content': 'Voc√™ √© um especialista em cria√ß√£o de conte√∫do e storytelling para YouTube.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 2000,
                'temperature': 0.8
            },
            timeout=60
        )
        
        if response.status_code != 200:
            raise Exception(f'OpenRouter API error: {response.status_code} - {response.text}')
        
        data = response.json()
        content = data['choices'][0]['message']['content']
        
        return parse_premises_response(content, titles)
        
    except Exception as e:
        raise Exception(f'Erro OpenRouter: {str(e)}')

def generate_premises_gemini(titles, prompt, title_generator):
    """Gerar premissas usando Gemini"""
    try:
        if not title_generator.gemini_model:
            raise Exception('Gemini n√£o configurado')

        print(f"üîç DEBUG: Prompt enviado para Gemini (primeiros 500 chars): {prompt[:500]}...")

        response = title_generator.gemini_model.generate_content(prompt)
        content = response.text

        return parse_premises_response(content, titles)

    except Exception as e:
        raise Exception(f'Erro Gemini: {str(e)}')

def generate_premises_openai(titles, prompt, title_generator):
    """Gerar premissas usando OpenAI"""
    try:
        if not title_generator.openai_client:
            raise Exception('OpenAI n√£o configurado')
        
        response = title_generator.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de conte√∫do e storytelling para YouTube."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.8
        )
        
        content = response.choices[0].message.content
        
        return parse_premises_response(content, titles)
        
    except Exception as e:
        raise Exception(f'Erro OpenAI: {str(e)}')

def parse_premises_response(content, titles):
    """Parsear resposta da IA para extrair premissas"""
    premises = []

    print(f"üîç DEBUG: Parseando resposta da IA...")
    print(f"üîç DEBUG: T√≠tulos fornecidos: {titles}")
    print(f"üîç DEBUG: Conte√∫do da resposta (primeiros 500 chars): {content[:500]}...")

    try:
        # M√âTODO 1: Tentar parsing estruturado primeiro
        sections = content.split('---')
        print(f"üîç DEBUG: M√©todo 1 - Encontradas {len(sections)} se√ß√µes")

        for i, section in enumerate(sections):
            section = section.strip()
            if not section:
                continue

            print(f"üîç DEBUG: Processando se√ß√£o {i+1}: {section[:100]}...")

            # Procurar por padr√µes de t√≠tulo e premissa
            lines = section.split('\n')
            current_title = None
            current_premise = []

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Detectar t√≠tulo
                if line.startswith('**T√çTULO:**') or line.startswith('T√çTULO:'):
                    current_title = line.replace('**T√çTULO:**', '').replace('T√çTULO:', '').strip()
                    print(f"üîç DEBUG: T√≠tulo encontrado: '{current_title}'")
                elif line.startswith('**PREMISSA:**') or line.startswith('PREMISSA:'):
                    current_premise = []
                    print(f"üîç DEBUG: In√≠cio de premissa detectado")
                elif current_title and line:
                    current_premise.append(line)

            if current_title and current_premise:
                premise_text = '\n'.join(current_premise).strip()
                print(f"üîç DEBUG: Premissa encontrada - T√≠tulo: '{current_title}', Premissa: {len(premise_text)} chars")
                premises.append({
                    'title': current_title,
                    'premise': premise_text
                })

        # M√âTODO 2: Se n√£o encontrou nada, tentar parsing mais flex√≠vel
        if not premises:
            print(f"üîç DEBUG: M√©todo 1 falhou, tentando m√©todo 2 - parsing flex√≠vel...")

            # Tentar encontrar qualquer padr√£o de t√≠tulo seguido de texto
            lines = content.split('\n')
            current_title = None
            current_premise = []

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Procurar por qualquer linha que contenha um dos t√≠tulos fornecidos
                title_found = None
                for title in titles:
                    if title.lower() in line.lower() or line.lower() in title.lower():
                        title_found = title
                        break

                if title_found:
                    # Salvar premissa anterior se existir
                    if current_title and current_premise:
                        premise_text = '\n'.join(current_premise).strip()
                        print(f"üîç DEBUG: M√©todo 2 - Premissa encontrada: '{current_title}', {len(premise_text)} chars")
                        premises.append({
                            'title': current_title,
                            'premise': premise_text
                        })

                    current_title = title_found
                    current_premise = []
                    print(f"üîç DEBUG: M√©todo 2 - Novo t√≠tulo: '{current_title}'")
                elif current_title and line and not line.startswith('#'):
                    current_premise.append(line)

            # Adicionar √∫ltima premissa
            if current_title and current_premise:
                premise_text = '\n'.join(current_premise).strip()
                print(f"üîç DEBUG: M√©todo 2 - √öltima premissa: '{current_title}', {len(premise_text)} chars")
                premises.append({
                    'title': current_title,
                    'premise': premise_text
                })
        
        # M√âTODO 3: Se ainda n√£o encontrou nada, criar premissas baseadas no conte√∫do completo
        if not premises and titles:
            print(f"üîç DEBUG: M√©todos 1 e 2 falharam, tentando m√©todo 3 - divis√£o por t√≠tulos...")
            # Dividir por t√≠tulos conhecidos
            for title in titles:
                if title in content:
                    # Encontrar a se√ß√£o deste t√≠tulo
                    start_idx = content.find(title)
                    if start_idx != -1:
                        # Procurar pr√≥ximo t√≠tulo ou fim
                        end_idx = len(content)
                        for other_title in titles:
                            if other_title != title:
                                other_idx = content.find(other_title, start_idx + len(title))
                                if other_idx != -1 and other_idx < end_idx:
                                    end_idx = other_idx
                        
                        section = content[start_idx:end_idx].strip()
                        # Extrair premissa (tudo ap√≥s o t√≠tulo)
                        premise_text = section.replace(title, '').strip()
                        
                        # Limpar marcadores
                        premise_text = premise_text.replace('**PREMISSA:**', '').replace('PREMISSA:', '').strip()
                        
                        if premise_text:
                            print(f"üîç DEBUG: M√©todo 3 - Premissa criada: '{title}', {len(premise_text)} chars")
                            premises.append({
                                'title': title,
                                'premise': premise_text
                            })

        # M√âTODO 4: Se ainda n√£o tem premissas, criar uma gen√©rica baseada no conte√∫do completo
        if not premises and titles and content.strip():
            print(f"üîç DEBUG: M√©todo 4 - Criando premissas gen√©ricas baseadas no conte√∫do...")
            # Dividir o conte√∫do em partes iguais para cada t√≠tulo
            content_clean = content.strip()
            content_per_title = len(content_clean) // len(titles)

            for i, title in enumerate(titles):
                start_pos = i * content_per_title
                end_pos = (i + 1) * content_per_title if i < len(titles) - 1 else len(content_clean)
                premise_text = content_clean[start_pos:end_pos].strip()

                if premise_text:
                    print(f"üîç DEBUG: M√©todo 4 - Premissa gen√©rica: '{title}', {len(premise_text)} chars")
                    premises.append({
                        'title': title,
                        'premise': premise_text
                    })

        print(f"üîç DEBUG: Total de premissas parseadas: {len(premises)}")
        return premises

    except Exception as e:
        print(f"‚ùå Erro ao parsear premissas: {e}")
        print(f"üîç DEBUG: Usando fallback - criando premissas gen√©ricas para {len(titles)} t√≠tulos")
        # Fallback: criar uma premissa gen√©rica para cada t√≠tulo
        fallback_premises = [
            {
                'title': title,
                'premise': f"Premissa gerada para: {title}\n\nEsta √© uma premissa de exemplo que seria desenvolvida com base no t√≠tulo fornecido."
            }
            for title in titles
        ]
        print(f"üîç DEBUG: Fallback criou {len(fallback_premises)} premissas")
        return fallback_premises

# Fun√ß√µes auxiliares para gera√ß√£o em partes
def create_inicio_prompt(title, premise, custom_prompt):
    """Criar prompt limpo para a parte IN√çCIO"""
    return f"""## INFORMA√á√ïES DO PROJETO:
### T√çTULO: {title}
### PREMISSA: {premise}
### üé≠ Prompt Personalizado do Agente:
{custom_prompt}

## INSTRU√á√ÉO ESPEC√çFICA:
Gere a parte INICIAL do roteiro (aproximadamente 25% do roteiro total) seguindo EXATAMENTE o formato especificado no prompt personalizado acima. Esta √© a PRIMEIRA parte de um roteiro maior."""

def create_capitulo_prompt(title, premise, custom_prompt, capitulo_num, total_capitulos):
    """Criar prompt limpo para um cap√≠tulo"""
    return f"""## INFORMA√á√ïES DO PROJETO:
### T√çTULO: {title}
### PREMISSA: {premise}
### üé≠ Prompt Personalizado do Agente:
{custom_prompt}

## INSTRU√á√ÉO ESPEC√çFICA:
Gere o CAP√çTULO {capitulo_num} de {total_capitulos} do desenvolvimento do roteiro seguindo EXATAMENTE o formato especificado no prompt personalizado acima. Esta √© uma parte INTERMEDI√ÅRIA de um roteiro maior."""

def create_final_prompt(title, premise, custom_prompt):
    """Criar prompt limpo para a parte FINAL"""
    return f"""## INFORMA√á√ïES DO PROJETO:
### T√çTULO: {title}
### PREMISSA: {premise}
### üé≠ Prompt Personalizado do Agente:
{custom_prompt}

## INSTRU√á√ÉO ESPEC√çFICA:
Gere a parte FINAL do roteiro (aproximadamente 25% final do roteiro total) seguindo EXATAMENTE o formato especificado no prompt personalizado acima. Esta √© a √öLTIMA parte que finaliza todo o roteiro."""

def generate_script_part(prompt, ai_provider, openrouter_model, api_keys, title_generator):
    """Gerar uma parte espec√≠fica do roteiro"""
    try:
        if ai_provider == 'openrouter':
            if 'openrouter' not in api_keys:
                raise Exception('Chave OpenRouter n√£o fornecida')
            return generate_script_openrouter(prompt, openrouter_model, api_keys['openrouter'])

        elif ai_provider == 'openai':
            if 'openai' not in api_keys:
                raise Exception('Chave OpenAI n√£o fornecida')
            return generate_script_openai(prompt, title_generator)

        else:  # gemini (padr√£o)
            # Verificar se o Gemini foi configurado corretamente
            if not title_generator.gemini_model:
                gemini_keys = [key for key in api_keys.keys() if key.startswith('gemini')]
                if not gemini_keys:
                    raise Exception('Nenhuma chave Gemini encontrada')
                else:
                    raise Exception('Gemini n√£o foi configurado corretamente')
            return generate_script_gemini(prompt, title_generator)

    except Exception as e:
        print(f"‚ùå [AGENTE] Erro ao gerar parte: {e}")
        return f"[ERRO NA GERA√á√ÉO DESTA PARTE: {str(e)}]"

@premise_bp.route('/generate-agent-script', methods=['POST'])
def generate_agent_script():
    """
    üé¨ Endpoint espec√≠fico para o Agente IA de Roteiros
    Gera roteiros extensos baseados em t√≠tulo, premissa e prompt personalizado
    """
    try:
        data = request.get_json()

        # Validar dados obrigat√≥rios
        if not data:
            return jsonify({
                'success': False,
                'error': 'Dados n√£o fornecidos'
            }), 400

        title = data.get('title', '').strip()
        premise = data.get('premise', '').strip()
        custom_prompt = data.get('custom_prompt', '').strip()
        ai_provider = data.get('ai_provider', 'gemini').lower()
        openrouter_model = data.get('openrouter_model', 'auto')
        api_keys = data.get('api_keys', {})
        num_chapters = data.get('num_chapters', 3)  # N√∫mero de cap√≠tulos (1-8)

        print(f"üé¨ [AGENTE] Iniciando gera√ß√£o de roteiro extenso em partes...")
        print(f"üìù [AGENTE] T√≠tulo: {title[:100]}...")
        print(f"üéØ [AGENTE] Premissa: {premise[:100]}...")
        print(f"üìÑ [AGENTE] Prompt personalizado: {len(custom_prompt)} caracteres")
        print(f"üìö [AGENTE] N√∫mero de cap√≠tulos: {num_chapters}")
        print(f"ü§ñ [AGENTE] Provider: {ai_provider}")

        if not title:
            return jsonify({
                'success': False,
                'error': 'T√≠tulo √© obrigat√≥rio'
            }), 400

        if not premise:
            return jsonify({
                'success': False,
                'error': 'Premissa √© obrigat√≥ria'
            }), 400

        if not custom_prompt:
            return jsonify({
                'success': False,
                'error': 'Prompt personalizado √© obrigat√≥rio'
            }), 400

        # Gerar roteiro em partes para contornar limita√ß√µes de tokens
        print(f"üîÑ [AGENTE] Iniciando gera√ß√£o em {2 + num_chapters} partes...")

        script_parts = []
        total_characters = 0

        # Configurar TitleGenerator para usar as chaves fornecidas
        title_generator = TitleGenerator()

        # Configurar chaves de API individualmente
        if api_keys:
            if api_keys.get('openai'):
                title_generator.configure_openai(api_keys['openai'])
            if api_keys.get('openrouter'):
                title_generator.configure_openrouter(api_keys['openrouter'])
            # Configurar Gemini (tentar todas as chaves dispon√≠veis)
            gemini_keys = [key for key in api_keys.keys() if key.startswith('gemini')]
            for gemini_key in gemini_keys:
                if title_generator.configure_gemini(api_keys[gemini_key]):
                    break  # Usar a primeira chave que funcionar

        # PARTE 1: IN√çCIO (Abertura + Introdu√ß√£o)
        print(f"üìù [AGENTE] Gerando PARTE 1: IN√çCIO...")
        inicio_prompt = create_inicio_prompt(title, premise, custom_prompt)
        inicio_content = generate_script_part(inicio_prompt, ai_provider, openrouter_model, api_keys, title_generator)
        script_parts.append({
            'part': 'IN√çCIO',
            'content': inicio_content,
            'characters': len(inicio_content)
        })
        total_characters += len(inicio_content)
        print(f"‚úÖ [AGENTE] IN√çCIO gerado: {len(inicio_content)} caracteres")

        # PARTES 2 a N: CAP√çTULOS
        for i in range(1, num_chapters + 1):
            print(f"üìñ [AGENTE] Gerando CAP√çTULO {i}/{num_chapters}...")
            capitulo_prompt = create_capitulo_prompt(title, premise, custom_prompt, i, num_chapters)
            capitulo_content = generate_script_part(capitulo_prompt, ai_provider, openrouter_model, api_keys, title_generator)
            script_parts.append({
                'part': f'CAP√çTULO {i}',
                'content': capitulo_content,
                'characters': len(capitulo_content)
            })
            total_characters += len(capitulo_content)
            print(f"‚úÖ [AGENTE] CAP√çTULO {i} gerado: {len(capitulo_content)} caracteres")

        # PARTE FINAL: CONCLUS√ÉO
        print(f"üèÅ [AGENTE] Gerando PARTE FINAL: CONCLUS√ÉO...")
        final_prompt = create_final_prompt(title, premise, custom_prompt)
        final_content = generate_script_part(final_prompt, ai_provider, openrouter_model, api_keys, title_generator)
        script_parts.append({
            'part': 'CONCLUS√ÉO',
            'content': final_content,
            'characters': len(final_content)
        })
        total_characters += len(final_content)
        print(f"‚úÖ [AGENTE] CONCLUS√ÉO gerada: {len(final_content)} caracteres")

        # CONCATENAR TODAS AS PARTES
        print(f"üîó [AGENTE] Concatenando {len(script_parts)} partes...")
        full_script = "\n\n".join([part['content'] for part in script_parts])

        print(f"üéâ [AGENTE] ROTEIRO COMPLETO GERADO!")
        print(f"üìä [AGENTE] Estat√≠sticas finais:")
        print(f"  - Total de partes: {len(script_parts)}")
        print(f"  - Caracteres totais: {len(full_script)}")
        print(f"  - Palavras estimadas: {len(full_script.split())}")
        print(f"  - Dura√ß√£o estimada: {len(full_script) // 200} minutos")

        for part in script_parts:
            print(f"    ‚Ä¢ {part['part']}: {part['characters']} chars")

        return jsonify({
            'success': True,
            'script': {
                'title': title,
                'premise': premise,
                'content': full_script,
                'character_count': len(full_script),
                'word_count': len(full_script.split()),
                'estimated_duration_minutes': len(full_script) // 200,
                'parts': script_parts,
                'num_chapters': num_chapters
            },
            'provider_used': ai_provider,
            'generation_method': 'multi_part'
        })

    except Exception as e:
        print(f"‚ùå [AGENTE] Erro na gera√ß√£o do roteiro: {e}")
        return jsonify({
            'success': False,
            'error': f'Erro na gera√ß√£o do roteiro: {str(e)}'
        }), 500



def generate_script_openrouter(prompt, model, api_key):
    """Gerar roteiro extenso usando OpenRouter"""
    try:
        if model == 'auto':
            model = 'anthropic/claude-3.5-sonnet'

        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:5173',
            'X-Title': 'Auto Video Producer - Agent Script Generator'
        }

        response = requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers,
            json={
                'model': model,
                'messages': [
                    {
                        'role': 'system',
                        'content': 'Voc√™ √© um roteirista profissional especializado em seguir EXATAMENTE as instru√ß√µes de formato fornecidas pelo usu√°rio. Voc√™ NUNCA inventa seu pr√≥prio formato - sempre segue precisamente o que foi solicitado. Sua especialidade √© criar roteiros extensos e detalhados seguindo rigorosamente as especifica√ß√µes fornecidas.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 8000,  # M√°ximo para roteiros extensos
                'temperature': 0.3  # Menor temperatura para seguir instru√ß√µes mais fielmente
            },
            timeout=120  # Timeout maior para roteiros extensos
        )

        if response.status_code != 200:
            raise Exception(f'OpenRouter API error: {response.status_code} - {response.text}')

        data = response.json()
        content = data['choices'][0]['message']['content']

        print(f"üîç [AGENTE] OpenRouter gerou {len(content)} caracteres")
        return content

    except Exception as e:
        raise Exception(f'Erro OpenRouter: {str(e)}')

def generate_script_gemini(prompt, title_generator):
    """Gerar roteiro extenso usando Gemini"""
    try:
        if not title_generator.gemini_model:
            raise Exception('Gemini n√£o configurado')

        print(f"üîç [AGENTE] Enviando prompt para Gemini ({len(prompt)} chars)...")

        response = title_generator.gemini_model.generate_content(prompt)
        content = response.text

        print(f"üîç [AGENTE] Gemini gerou {len(content)} caracteres")
        return content

    except Exception as e:
        raise Exception(f'Erro Gemini: {str(e)}')

def generate_script_openai(prompt, title_generator):
    """Gerar roteiro extenso usando OpenAI"""
    try:
        if not title_generator.openai_client:
            raise Exception('OpenAI n√£o configurado')

        response = title_generator.openai_client.chat.completions.create(
            model="gpt-4",  # Usar GPT-4 para roteiros mais extensos
            messages=[
                {"role": "system", "content": "Voc√™ √© um roteirista profissional especializado em seguir EXATAMENTE as instru√ß√µes de formato fornecidas pelo usu√°rio. Voc√™ NUNCA inventa seu pr√≥prio formato - sempre segue precisamente o que foi solicitado. Sua especialidade √© criar roteiros extensos e detalhados seguindo rigorosamente as especifica√ß√µes fornecidas."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=8000,  # M√°ximo para roteiros extensos
            temperature=0.3  # Menor temperatura para seguir instru√ß√µes mais fielmente
        )

        content = response.choices[0].message.content

        print(f"üîç [AGENTE] OpenAI gerou {len(content)} caracteres")
        return content

    except Exception as e:
        raise Exception(f'Erro OpenAI: {str(e)}')
