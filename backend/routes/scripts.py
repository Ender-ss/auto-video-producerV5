"""
ğŸ“ Script Generation Routes
Rotas para geraÃ§Ã£o de roteiros com pipeline de 3 prompts
"""

from flask import Blueprint, request, jsonify
import requests
import json
import time
from services.title_generator import TitleGenerator

scripts_bp = Blueprint('scripts', __name__)

@scripts_bp.route('/generate', methods=['POST'])
def generate_scripts():
    """Gerar roteiros usando pipeline de 3 prompts"""
    try:
        data = request.get_json()
        title = data.get('title', '')
        premise = data.get('premise', '')
        ai_provider = data.get('ai_provider', 'auto')
        openrouter_model = data.get('openrouter_model', 'auto')
        number_of_chapters = data.get('number_of_chapters', 8)
        api_keys = data.get('api_keys', {})

        if not title or not premise:
            return jsonify({
                'success': False,
                'error': 'TÃ­tulo e premissa sÃ£o obrigatÃ³rios'
            }), 400

        # Inicializar o gerador
        title_generator = TitleGenerator()
        
        # Configurar APIs baseado no provider
        if ai_provider == 'openai' or ai_provider == 'auto':
            if api_keys.get('openai'):
                title_generator.configure_openai(api_keys['openai'])
        
        if ai_provider == 'gemini' or ai_provider == 'auto':
            gemini_key = api_keys.get('gemini') or api_keys.get('gemini_1')
            if gemini_key:
                title_generator.configure_gemini(gemini_key)
        
        if ai_provider == 'openrouter' or ai_provider == 'auto':
            if api_keys.get('openrouter'):
                title_generator.configure_openrouter(api_keys['openrouter'])

        # Pipeline de 3 prompts
        print("ğŸ¬ Iniciando pipeline de geraÃ§Ã£o de roteiros...")
        
        # PROMPT 1: TraduÃ§Ã£o e Contexto
        print("ğŸ“ Executando Prompt 1: TraduÃ§Ã£o e Contexto")
        context_result = execute_prompt_1(title, premise, ai_provider, openrouter_model, api_keys, title_generator)
        
        if not context_result:
            raise Exception("Falha no Prompt 1: TraduÃ§Ã£o e Contexto")
        
        # PROMPT 2: Estrutura Narrativa
        print("ğŸ“– Executando Prompt 2: Estrutura Narrativa")
        narrative_result = execute_prompt_2(title, context_result, ai_provider, openrouter_model, api_keys, title_generator)
        
        if not narrative_result:
            raise Exception("Falha no Prompt 2: Estrutura Narrativa")
        
        # PROMPT 3: GeraÃ§Ã£o dos CapÃ­tulos
        print(f"âœï¸ Executando Prompt 3: GeraÃ§Ã£o de {number_of_chapters} CapÃ­tulos")
        chapters = execute_prompt_3(title, context_result, narrative_result, number_of_chapters, ai_provider, openrouter_model, api_keys, title_generator)
        
        if not chapters:
            raise Exception("Falha no Prompt 3: GeraÃ§Ã£o dos CapÃ­tulos")

        # Resultado final
        script_result = {
            'title': title,
            'premise': premise,
            'context': context_result,
            'narrative_structure': narrative_result,
            'chapters': chapters,
            'total_chapters': len(chapters),
            'total_words': sum(len(ch['content'].split()) for ch in chapters if ch.get('content'))
        }

        return jsonify({
            'success': True,
            'scripts': script_result,
            'provider_used': ai_provider,
            'chapters_generated': len(chapters)
        })

    except Exception as e:
        print(f"âŒ Erro na geraÃ§Ã£o de roteiros: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def execute_prompt_1(title, premise, ai_provider, openrouter_model, api_keys, title_generator):
    """Prompt 1: TraduÃ§Ã£o e Contexto"""
    prompt = f"""Por favor, forneÃ§a o texto acima em PortuguÃªs, utilizando nomes e expressÃµes comuns entre os falantes de PortuguÃªs em diferentes paÃ­ses, adaptado de forma a refletir a cultura compartilhada pelos diversos povos que falam a lÃ­ngua. Adapte nomes, locais e referÃªncias culturais de forma a serem naturais e reconhecÃ­veis no idioma PortuguÃªs, garantindo que mantenham relevÃ¢ncia e ressoem com o pÃºblico.

A saÃ­da deve ter o seguinte formato:

{{
    "Contexto": "{premise}"
}}

Certifique-se de que a chave gerada siga o padrÃ£o exigido."""

    try:
        if ai_provider == 'auto':
            providers = ['openrouter', 'gemini', 'openai']
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
                    elif provider == 'gemini' and title_generator.gemini_model:
                        return call_gemini(prompt, title_generator)
                    elif provider == 'openai' and title_generator.openai_client:
                        return call_openai(prompt, title_generator)
                except Exception as e:
                    print(f"âŒ Erro com {provider}: {e}")
                    continue
        elif ai_provider == 'openrouter':
            return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
        elif ai_provider == 'gemini':
            return call_gemini(prompt, title_generator)
        elif ai_provider == 'openai':
            return call_openai(prompt, title_generator)
            
        return None
    except Exception as e:
        print(f"âŒ Erro no Prompt 1: {e}")
        return None

def execute_prompt_2(title, context, ai_provider, openrouter_model, api_keys, title_generator):
    """Prompt 2: Estrutura Narrativa"""
    prompt = f"""# Objetivo Principal: 

Transformar qualquer tema em um Ãºnico prompt narrativo para o primeiro capÃ­tulo, sem finalizar a histÃ³ria. O resultado serÃ¡ um array JSON chamado `Prompts`, que conterÃ¡ exatamente 1 objeto, com o campo `prompt`.

## Tema: "{title}"
### Contexto: "{context}"

## Estrutura Base do Prompt  
Cada prompt deve comeÃ§ar com: "Escreva uma histÃ³ria de aproximadamente 500 palavras sobre..."  

## EspecificaÃ§Ãµes TÃ©cnicas do JSON

```json
{{
  "Prompts": [
    {{
      "prompt": "Escreva uma histÃ³ria de aproximadamente 500 palavras sobre..."
    }}
  ]
}}
```

## Requisitos TÃ©cnicos 

- Apenas um objeto no array `Prompts`  
- Cadeia com aspas duplas  
- IndentaÃ§Ã£o: 2 espaÃ§os  
- Sem quebras de linha no conteÃºdo de `prompt`  
- JSON vÃ¡lido e com caracteres especiais escapados  

## Estrutura Narrativa Detalhada (Apenas Primeiro CapÃ­tulo)

1. **ApresentaÃ§Ã£o do Protagonista**  
   - Nome e caracterÃ­sticas principais  
   - Contexto social/profissional  
   - Estado emocional inicial  

2. **CenÃ¡rio Principal**  
   - LocalizaÃ§Ã£o temporal e espacial  
   - Atmosfera e ambiente  
   - Elementos Ãºnicos do mundo da histÃ³ria  

3. **Ativador da HistÃ³ria**  
   - Evento catalisador que rompa a normalidade  
   - Inicie o conflito inicial ou dilema principal  

4. **Gancho Narrativo**  
   - Elemento de mistÃ©rio ou tensÃ£o que deixe clara a continuaÃ§Ã£o  
   - Pergunta nÃ£o resolvida  
   - Termine sem concluir o conflito, mantendo a histÃ³ria incompleta 

## Checklist de ValidaÃ§Ã£o

1. **JSON**  
   - [ ] Apenas 1 objeto dentro de "Prompts"  
   - [ ] Campo "prompt" sem quebras de linha  
   - [ ] Cadeias com aspas duplas, sem caracteres especiais 

2. **Narrativa**  
   - [ ] HistÃ³ria NÃƒO finalizada (o capÃ­tulo fica em aberto)    
   - [ ] Inclui ganchos, sem resolver o conflito  
   - [ ] NÃ£o conclua a trama nem resolva o conflito principal. Em vez disso, crie um problema a partir de cada soluÃ§Ã£o, fazendo o leitor sentir que a histÃ³ria ainda precisa continuar. A sensaÃ§Ã£o final deve ser de que hÃ¡ mais por vir, nunca uma conclusÃ£o definitiva.  
   - [ ] Certifique-se de que o capÃ­tulo termine com um gancho intrigante, criando um mistÃ©rio ou uma dÃºvida que deixe o leitor ansioso pelo prÃ³ximo capÃ­tulo, sem conseguir parar de ler.  
   - [ ] Mantenha um equilÃ­brio entre aÃ§Ã£o e reflexÃ£o, permitindo que o personagem evolua, mas sem dar respostas definitivas ou conclusÃµes que resolvam os dilemas abertos.

## ObservaÃ§Ã£o Final

- NÃ£o conclua a trama nem resolva o conflito principal. Em vez disso, crie um problema a partir de cada soluÃ§Ã£o, fazendo o leitor sentir que a histÃ³ria ainda precisa continuar. A sensaÃ§Ã£o final deve ser que hÃ¡ mais por vir, nunca uma conclusÃ£o definitiva.  
- Certifique-se de que o capÃ­tulo termine com um gancho intrigante, criando um mistÃ©rio ou uma dÃºvida que deixe o leitor ansioso pelo prÃ³ximo capÃ­tulo, sem conseguir parar de ler.  
- Mantenha um equilÃ­brio entre aÃ§Ã£o e reflexÃ£o, permitindo que o personagem evolua, mas sem dar respostas definitivas ou conclusÃµes que resolvam os dilemas abertos."""

    try:
        if ai_provider == 'auto':
            providers = ['openrouter', 'gemini', 'openai']
            for provider in providers:
                try:
                    if provider == 'openrouter' and api_keys.get('openrouter'):
                        return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
                    elif provider == 'gemini' and title_generator.gemini_model:
                        return call_gemini(prompt, title_generator)
                    elif provider == 'openai' and title_generator.openai_client:
                        return call_openai(prompt, title_generator)
                except Exception as e:
                    print(f"âŒ Erro com {provider}: {e}")
                    continue
        elif ai_provider == 'openrouter':
            return call_openrouter(prompt, openrouter_model, api_keys['openrouter'])
        elif ai_provider == 'gemini':
            return call_gemini(prompt, title_generator)
        elif ai_provider == 'openai':
            return call_openai(prompt, title_generator)
            
        return None
    except Exception as e:
        print(f"âŒ Erro no Prompt 2: {e}")
        return None

def execute_prompt_3(title, context, narrative_structure, number_of_chapters, ai_provider, openrouter_model, api_keys, title_generator):
    """Prompt 3: GeraÃ§Ã£o dos CapÃ­tulos"""
    chapters = []

    try:
        print(f"ğŸ” DEBUG: Iniciando geraÃ§Ã£o de {number_of_chapters} capÃ­tulos")
        print(f"ğŸ” DEBUG: AI Provider: {ai_provider}")
        print(f"ğŸ” DEBUG: APIs disponÃ­veis: {list(api_keys.keys())}")

        # Verificar se hÃ¡ pelo menos uma API configurada
        has_openrouter = api_keys.get('openrouter') is not None
        has_gemini = title_generator.gemini_model is not None
        has_openai = title_generator.openai_client is not None

        print(f"ğŸ” DEBUG: OpenRouter: {'âœ…' if has_openrouter else 'âŒ'}")
        print(f"ğŸ” DEBUG: Gemini: {'âœ…' if has_gemini else 'âŒ'}")
        print(f"ğŸ” DEBUG: OpenAI: {'âœ…' if has_openai else 'âŒ'}")

        if not (has_openrouter or has_gemini or has_openai):
            print("âŒ ERRO: Nenhuma API de IA configurada para geraÃ§Ã£o de roteiros")
            return []

        # Extrair o prompt base da estrutura narrativa
        base_prompt = extract_base_prompt(narrative_structure)
        print(f"ğŸ” DEBUG: Base prompt extraÃ­do: {base_prompt[:100]}...")
        
        for i in range(number_of_chapters):
            print(f"ğŸ“– Gerando CapÃ­tulo {i + 1}/{number_of_chapters}")
            
            if i == 0:
                # Primeiro capÃ­tulo usa o prompt base
                chapter_prompt = base_prompt
            else:
                # CapÃ­tulos seguintes continuam a histÃ³ria
                previous_chapter = chapters[i-1]['content'] if chapters else ""
                chapter_prompt = f"""Continue a histÃ³ria a partir do capÃ­tulo anterior. Escreva o prÃ³ximo capÃ­tulo de aproximadamente 500 palavras.

CapÃ­tulo anterior:
{previous_chapter}

InstruÃ§Ãµes:
- Continue a narrativa de forma natural
- Mantenha a consistÃªncia dos personagens
- Adicione novos elementos de tensÃ£o
- Termine com um gancho para o prÃ³ximo capÃ­tulo
- NÃƒO resolva o conflito principal ainda"""

            # Gerar o capÃ­tulo
            chapter_content = None
            print(f"ğŸ” DEBUG: Gerando capÃ­tulo {i+1} com prompt de {len(chapter_prompt)} caracteres")

            if ai_provider == 'auto':
                providers = ['openrouter', 'gemini', 'openai']
                for provider in providers:
                    try:
                        print(f"ğŸ” DEBUG: Tentando provider {provider}")
                        if provider == 'openrouter' and api_keys.get('openrouter'):
                            print(f"ğŸ” DEBUG: Chamando OpenRouter...")
                            chapter_content = call_openrouter(chapter_prompt, openrouter_model, api_keys['openrouter'])
                            print(f"âœ… DEBUG: OpenRouter retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        elif provider == 'gemini' and title_generator.gemini_model:
                            print(f"ğŸ” DEBUG: Chamando Gemini...")
                            chapter_content = call_gemini(chapter_prompt, title_generator)
                            print(f"âœ… DEBUG: Gemini retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        elif provider == 'openai' and title_generator.openai_client:
                            print(f"ğŸ” DEBUG: Chamando OpenAI...")
                            chapter_content = call_openai(chapter_prompt, title_generator)
                            print(f"âœ… DEBUG: OpenAI retornou {len(chapter_content) if chapter_content else 0} caracteres")
                            break
                        else:
                            print(f"âš ï¸ DEBUG: Provider {provider} nÃ£o disponÃ­vel")
                    except Exception as e:
                        print(f"âŒ Erro com {provider}: {e}")
                        continue
            elif ai_provider == 'openrouter':
                chapter_content = call_openrouter(chapter_prompt, openrouter_model, api_keys['openrouter'])
            elif ai_provider == 'gemini':
                chapter_content = call_gemini(chapter_prompt, title_generator)
            elif ai_provider == 'openai':
                chapter_content = call_openai(chapter_prompt, title_generator)
            
            if chapter_content:
                # Gerar tÃ­tulo do capÃ­tulo baseado no conteÃºdo
                chapter_title = f"CapÃ­tulo {i + 1}"
                if len(chapter_content) > 50:
                    # Tentar extrair uma frase inicial como tÃ­tulo
                    first_sentence = chapter_content.split('.')[0][:50]
                    if len(first_sentence) > 10:
                        chapter_title = f"CapÃ­tulo {i + 1}: {first_sentence}..."

                chapters.append({
                    'chapter_number': i + 1,
                    'title': chapter_title,
                    'content': chapter_content,
                    'word_count': len(chapter_content.split())
                })
            else:
                print(f"âŒ Falha ao gerar capÃ­tulo {i + 1}")
                # Se Ã© o primeiro capÃ­tulo e falhou, retornar erro
                if i == 0:
                    print(f"âŒ ERRO CRÃTICO: Falha ao gerar o primeiro capÃ­tulo")
                    return []
                # Se nÃ£o Ã© o primeiro, continuar com os capÃ­tulos jÃ¡ gerados
                break

            # Pequena pausa entre capÃ­tulos para evitar rate limiting
            time.sleep(1)

        print(f"âœ… DEBUG: Gerados {len(chapters)} capÃ­tulos com sucesso")
        return chapters
        
    except Exception as e:
        print(f"âŒ Erro no Prompt 3: {e}")
        return []

def extract_base_prompt(narrative_structure):
    """Extrair o prompt base da estrutura narrativa"""
    try:
        if isinstance(narrative_structure, str):
            # Tentar parsear como JSON
            import json
            data = json.loads(narrative_structure)
            if 'Prompts' in data and len(data['Prompts']) > 0:
                return data['Prompts'][0].get('prompt', narrative_structure)
        return narrative_structure
    except:
        return narrative_structure

def call_openrouter(prompt, model, api_key):
    """Chamar OpenRouter API"""
    try:
        print(f"ğŸ” DEBUG: Enviando prompt para OpenRouter ({len(prompt)} chars)")
        if model == 'auto':
            model = 'anthropic/claude-3.5-sonnet'
        print(f"ğŸ” DEBUG: Usando modelo: {model}")
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:5173',
            'X-Title': 'Auto Video Producer'
        }
        
        response = requests.post(
            'https://openrouter.ai/api/v1/chat/completions',
            headers=headers,
            json={
                'model': model,
                'messages': [
                    {'role': 'system', 'content': 'VocÃª Ã© um especialista em criaÃ§Ã£o de roteiros e storytelling.'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 2000,
                'temperature': 0.8
            },
            timeout=60
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data['choices'][0]['message']['content']
            print(f"ğŸ” DEBUG: OpenRouter respondeu com {len(content)} caracteres")
            return content
        else:
            print(f"âŒ DEBUG: OpenRouter erro {response.status_code}: {response.text}")
            raise Exception(f'OpenRouter API error: {response.status_code}')

    except Exception as e:
        print(f"âŒ DEBUG: Erro detalhado no OpenRouter: {str(e)}")
        raise Exception(f'Erro OpenRouter: {str(e)}')

def call_gemini(prompt, title_generator):
    """Chamar Gemini API"""
    try:
        print(f"ğŸ” DEBUG: Enviando prompt para Gemini ({len(prompt)} chars)")
        response = title_generator.gemini_model.generate_content(prompt)
        print(f"ğŸ” DEBUG: Gemini respondeu com {len(response.text)} caracteres")
        return response.text
    except Exception as e:
        print(f"âŒ DEBUG: Erro detalhado no Gemini: {str(e)}")
        raise Exception(f'Erro Gemini: {str(e)}')

def call_openai(prompt, title_generator):
    """Chamar OpenAI API"""
    try:
        print(f"ğŸ” DEBUG: Enviando prompt para OpenAI ({len(prompt)} chars)")
        response = title_generator.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "VocÃª Ã© um especialista em criaÃ§Ã£o de roteiros e storytelling."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.8
        )
        content = response.choices[0].message.content
        print(f"ğŸ” DEBUG: OpenAI respondeu com {len(content)} caracteres")
        return content
    except Exception as e:
        print(f"âŒ DEBUG: Erro detalhado no OpenAI: {str(e)}")
        raise Exception(f'Erro OpenAI: {str(e)}')
