"""
ü§ñ Servi√ßo de Gera√ß√£o de T√≠tulos com IA
Auto Video Producer - Gera√ß√£o inteligente de t√≠tulos virais
"""

import google.generativeai as genai
import json
import re
import random
from typing import List, Dict, Optional
import requests
import time

class TitleGenerator:
    def __init__(self):
        self.openai_client = None
        self.gemini_model = None
        self.openrouter_api_key = None
        
    def configure_openai(self, api_key: str):
        """Configurar cliente OpenAI"""
        try:
            print(f"üîç DEBUG: Tentando configurar OpenAI com chave: {api_key[:20]}...")
            from openai import OpenAI
            print("üîç DEBUG: Biblioteca OpenAI importada com sucesso")

            # Validar formato da chave
            if not api_key.startswith('sk-'):
                print(f"‚ùå Chave OpenAI inv√°lida: deve come√ßar com 'sk-'")
                return False

            self.openai_client = OpenAI(api_key=api_key)
            print("üîç DEBUG: Cliente OpenAI criado com sucesso")

            # Testar a conex√£o fazendo uma chamada simples
            try:
                models = self.openai_client.models.list()
                print("üîç DEBUG: Teste de conex√£o OpenAI bem-sucedido")
                return True
            except Exception as test_error:
                print(f"‚ùå Erro no teste de conex√£o OpenAI: {test_error}")
                return False

        except ImportError as e:
            print(f"‚ùå Erro de importa√ß√£o OpenAI: {e}")
            print("üí° Instale a biblioteca: pip install openai")
            return False
        except Exception as e:
            print(f"‚ùå Erro ao configurar OpenAI: {e}")
            print(f"üîç DEBUG: Tipo do erro: {type(e)}")
            return False
            
    def configure_gemini(self, api_key: str):
        """Configurar cliente Google Gemini"""
        try:
            print(f"üîç DEBUG: Tentando configurar Gemini com chave: {api_key[:20]}...")
            genai.configure(api_key=api_key)
            print("üîç DEBUG: Gemini configurado com sucesso")
            # Usar o modelo mais recente dispon√≠vel
            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            print("‚úÖ Gemini configurado com modelo: gemini-1.5-flash")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao configurar Gemini: {e}")
            print(f"üîç DEBUG: Tipo do erro: {type(e)}")
            # Tentar modelo alternativo
            try:
                self.gemini_model = genai.GenerativeModel('gemini-1.5-pro')
                print("‚úÖ Gemini configurado com modelo alternativo: gemini-1.5-pro")
                return True
            except Exception as e2:
                print(f"‚ùå Erro ao configurar Gemini (modelo alternativo): {e2}")
                return False

    def configure_openrouter(self, api_key: str):
        """Configurar cliente OpenRouter"""
        try:
            self.openrouter_api_key = api_key
            print("‚úÖ OpenRouter configurado com sucesso")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao configurar OpenRouter: {e}")
            return False
    
    def analyze_viral_patterns(self, titles: List[str]) -> Dict:
        """Analisar padr√µes virais nos t√≠tulos extra√≠dos"""
        patterns = {
            'emotional_triggers': [],
            'numbers': [],
            'power_words': [],
            'structures': [],
            'length_stats': {
                'min': 0,
                'max': 0,
                'avg': 0
            }
        }
        
        # Palavras-chave emocionais comuns
        emotional_words = [
            'INCR√çVEL', 'CHOCANTE', 'SEGREDO', 'REVELADO', 'NUNCA', 'SEMPRE',
            'MELHOR', 'PIOR', '√öNICO', 'EXCLUSIVO', 'URGENTE', '√öLTIMO',
            'PRIMEIRO', 'NOVO', 'ANTIGO', 'R√ÅPIDO', 'F√ÅCIL', 'DIF√çCIL',
            'GR√ÅTIS', 'CARO', 'BARATO', 'RICO', 'POBRE', 'FAMOSO'
        ]
        
        # Analisar cada t√≠tulo
        lengths = []
        for title in titles:
            title_upper = title.upper()
            lengths.append(len(title))
            
            # Buscar gatilhos emocionais
            for word in emotional_words:
                if word in title_upper:
                    patterns['emotional_triggers'].append(word)
            
            # Buscar n√∫meros
            numbers = re.findall(r'\d+', title)
            patterns['numbers'].extend(numbers)
            
            # Buscar estruturas comuns
            if title.startswith('COMO'):
                patterns['structures'].append('COMO_FAZER')
            elif '?' in title:
                patterns['structures'].append('PERGUNTA')
            elif title.count('|') > 0:
                patterns['structures'].append('SEPARADOR')
            elif title.isupper():
                patterns['structures'].append('MAIUSCULA')
        
        # Calcular estat√≠sticas de comprimento
        if lengths:
            patterns['length_stats'] = {
                'min': min(lengths),
                'max': max(lengths),
                'avg': sum(lengths) / len(lengths)
            }
        
        # Remover duplicatas e contar frequ√™ncias
        patterns['emotional_triggers'] = list(set(patterns['emotional_triggers']))
        patterns['numbers'] = list(set(patterns['numbers']))
        patterns['structures'] = list(set(patterns['structures']))
        
        return patterns
    
    def generate_titles_openai(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> List[str]:
        """Gerar t√≠tulos usando OpenAI GPT"""
        if not self.openai_client:
            raise Exception("OpenAI n√£o configurado")
        
        # Analisar padr√µes dos t√≠tulos de origem
        patterns = self.analyze_viral_patterns(source_titles)
        
        # Criar prompt baseado nos padr√µes encontrados
        prompt = self.create_openai_prompt(source_titles, topic, patterns, style, count)
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.8
            )

            content = response.choices[0].message.content
            titles = self.parse_generated_titles(content)

            return titles[:count]
            
        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenAI: {e}")
            return []
    
    def generate_titles_gemini(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> List[str]:
        """Gerar t√≠tulos usando Google Gemini"""
        if not self.gemini_model:
            raise Exception("Gemini n√£o configurado")
        
        # Analisar padr√µes dos t√≠tulos de origem
        patterns = self.analyze_viral_patterns(source_titles)
        
        # Criar prompt baseado nos padr√µes encontrados
        prompt = self.create_gemini_prompt(source_titles, topic, patterns, style, count)
        
        try:
            print(f"üîç DEBUG: Enviando prompt para Gemini...")
            print(f"üîç DEBUG: T√≠tulos de origem: {source_titles}")
            print(f"üîç DEBUG: Quantidade solicitada: {count}")

            # Verificar cancelamento antes de chamar a IA
            try:
                from routes.workflow import check_workflow_status
                check_workflow_status()
            except:
                pass  # Se n√£o conseguir importar, continua

            response = self.gemini_model.generate_content(prompt)
            print(f"üîç DEBUG: Resposta bruta do Gemini: {response.text[:200]}...")

            titles = self.parse_generated_titles(response.text)
            print(f"üîç DEBUG: T√≠tulos parseados ({len(titles)}): {titles}")
            print(f"üîç DEBUG: Limitando para {count} t√≠tulos")

            limited_titles = titles[:count]
            print(f"üîç DEBUG: T√≠tulos finais ({len(limited_titles)}): {limited_titles}")

            return limited_titles

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o Gemini: {e}")
            return []
    
    def create_openai_prompt(self, source_titles: List[str], topic: str, patterns: Dict, style: str, count: int = 10) -> str:
        """Criar prompt otimizado para OpenAI"""
        prompt = f"""
Voc√™ √© um especialista em marketing digital para YouTube. Analise os t√≠tulos de refer√™ncia abaixo e crie NOVOS t√≠tulos SIMILARES mas MELHORADOS sobre o mesmo tema.

T√çTULOS DE REFER√äNCIA (extra√≠dos de canal de sucesso):
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles[:5]])}

PADR√ïES IDENTIFICADOS:
‚Ä¢ Gatilhos emocionais: {', '.join(patterns['emotional_triggers'][:10])}
‚Ä¢ N√∫meros populares: {', '.join(patterns['numbers'][:5])}
‚Ä¢ Estruturas: {', '.join(patterns['structures'])}
‚Ä¢ Comprimento m√©dio: {patterns['length_stats']['avg']:.0f} caracteres

INSTRU√á√ïES ESPEC√çFICAS:
1. üéØ MANTENHA o mesmo NICHO/TEMA dos t√≠tulos de refer√™ncia
2. üöÄ Crie 15 t√≠tulos SIMILARES mas MELHORADOS
3. üìà Use os padr√µes identificados para otimizar engajamento
4. üé™ Aplique gatilhos psicol√≥gicos mais fortes (curiosidade, urg√™ncia, exclusividade)
5. üî• Mantenha entre {patterns['length_stats']['min']} e {patterns['length_stats']['max']} caracteres
6. üí° Varie as estruturas mas mantenha o estilo {style}
7. üìä Foque em t√≠tulos que superem os originais em atratividade

IMPORTANTE: Os novos t√≠tulos devem ser sobre o MESMO TEMA dos t√≠tulos de refer√™ncia, mas mais otimizados para cliques.

FORMATO DE RESPOSTA:
1. [T√çTULO 1]
2. [T√çTULO 2]
...

IMPORTANTE: Gere EXATAMENTE {count} t√≠tulos, nem mais nem menos.

T√≠tulos ({count} t√≠tulos):
"""
        return prompt
    
    def create_gemini_prompt(self, source_titles: List[str], topic: str, patterns: Dict, style: str, count: int = 10) -> str:
        """Criar prompt otimizado para Gemini"""
        prompt = f"""
Voc√™ √© um especialista em marketing digital e cria√ß√£o de conte√∫do viral para YouTube.

TAREFA: Analisar os t√≠tulos de refer√™ncia abaixo e criar NOVOS t√≠tulos SIMILARES mas MELHORADOS sobre o mesmo tema/nicho.

T√çTULOS DE REFER√äNCIA (extra√≠dos de canal de sucesso):
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles[:5]])}

AN√ÅLISE DOS PADR√ïES IDENTIFICADOS:
‚Ä¢ Palavras-chave emocionais: {', '.join(patterns['emotional_triggers'][:8])}
‚Ä¢ N√∫meros eficazes: {', '.join(patterns['numbers'][:5])}
‚Ä¢ Estruturas que funcionam: {', '.join(patterns['structures'])}
‚Ä¢ Comprimento ideal: {patterns['length_stats']['min']}-{patterns['length_stats']['max']} caracteres

INSTRU√á√ïES ESPEC√çFICAS:
1. üéØ MANTENHA o mesmo NICHO/TEMA dos t√≠tulos de refer√™ncia
2. üöÄ MELHORE usando gatilhos psicol√≥gicos mais fortes
3. üìà OTIMIZE para maior engajamento e cliques
4. üé™ Use elementos de curiosidade, urg√™ncia, exclusividade
5. üî• Inclua emojis estrat√©gicos quando apropriado
6. üí° Varie as estruturas mas mantenha o estilo viral
7. üìä Crie t√≠tulos que superem os originais em atratividade

IMPORTANTE: Os novos t√≠tulos devem ser sobre o MESMO TEMA dos t√≠tulos de refer√™ncia, mas mais atrativos e otimizados.

FORMATO DE RESPOSTA:
Liste apenas os t√≠tulos numerados, um por linha:

1. [T√çTULO MELHORADO]
2. [T√çTULO MELHORADO]
...

IMPORTANTE: Gere EXATAMENTE {count} t√≠tulos, nem mais nem menos.

Gere os {count} t√≠tulos agora:
"""
        return prompt
    
    def parse_generated_titles(self, content: str) -> List[str]:
        """Extrair t√≠tulos do texto gerado pela IA"""
        titles = []

        print(f"üîç DEBUG: Parseando conte√∫do: {content[:200]}...")

        # Dividir por linhas
        lines = content.strip().split('\n')
        print(f"üîç DEBUG: {len(lines)} linhas encontradas")

        for i, line in enumerate(lines):
            original_line = line
            line = line.strip()

            # Remover numera√ß√£o (1., 2., etc.)
            line = re.sub(r'^\d+\.?\s*', '', line)

            # Remover marcadores (-, ‚Ä¢, etc.)
            line = re.sub(r'^[-‚Ä¢*]\s*', '', line)

            # Remover colchetes se existirem
            line = re.sub(r'^\[|\]$', '', line)

            print(f"üîç DEBUG: Linha {i+1}: '{original_line}' -> '{line}' (len: {len(line)})")

            # Verificar se √© um t√≠tulo v√°lido
            if line and len(line) > 10 and not line.startswith('T√≠tulo'):
                titles.append(line.strip())
                print(f"‚úÖ DEBUG: T√≠tulo aceito: '{line.strip()}'")
            else:
                print(f"‚ùå DEBUG: T√≠tulo rejeitado: '{line}' (muito curto ou inv√°lido)")

        print(f"üîç DEBUG: Total de t√≠tulos extra√≠dos: {len(titles)}")
        return titles
    
    def generate_titles_hybrid(self, 
                              source_titles: List[str], 
                              topic: str, 
                              count: int = 10,
                              style: str = "viral") -> Dict:
        """Gerar t√≠tulos usando m√∫ltiplas IAs e combinar resultados"""
        results = {
            'openai_titles': [],
            'gemini_titles': [],
            'combined_titles': [],
            'patterns_analysis': {},
            'success': False,
            'error': None
        }
        
        try:
            # Analisar padr√µes primeiro
            results['patterns_analysis'] = self.analyze_viral_patterns(source_titles)
            
            # Tentar OpenAI primeiro
            if self.openai_client:
                try:
                    openai_titles = self.generate_titles_openai(source_titles, topic, count, style)
                    results['openai_titles'] = openai_titles
                except Exception as e:
                    print(f"‚ö†Ô∏è OpenAI falhou: {e}")
            
            # Tentar Gemini como backup/complemento
            if self.gemini_model:
                try:
                    gemini_titles = self.generate_titles_gemini(source_titles, topic, count, style)
                    results['gemini_titles'] = gemini_titles
                except Exception as e:
                    print(f"‚ö†Ô∏è Gemini falhou: {e}")
            
            # Combinar e diversificar resultados
            all_titles = results['openai_titles'] + results['gemini_titles']
            
            if all_titles:
                # Remover duplicatas e selecionar os melhores
                unique_titles = list(dict.fromkeys(all_titles))  # Remove duplicatas mantendo ordem
                results['combined_titles'] = unique_titles[:count]
                results['success'] = True
            else:
                results['error'] = "Nenhuma IA conseguiu gerar t√≠tulos"
            
            return results
            
        except Exception as e:
            results['error'] = str(e)
            return results
    
    def score_title_quality(self, title: str, patterns: Dict) -> float:
        """Pontuar qualidade de um t√≠tulo baseado nos padr√µes virais"""
        score = 0.0
        title_upper = title.upper()

        # Pontua√ß√£o por gatilhos emocionais
        for trigger in patterns['emotional_triggers']:
            if trigger in title_upper:
                score += 2.0

        # Pontua√ß√£o por n√∫meros
        if re.search(r'\d+', title):
            score += 1.5

        # Pontua√ß√£o por comprimento ideal
        length = len(title)
        ideal_min = patterns['length_stats']['min']
        ideal_max = patterns['length_stats']['max']

        if ideal_min <= length <= ideal_max:
            score += 2.0
        elif abs(length - patterns['length_stats']['avg']) <= 10:
            score += 1.0

        # Pontua√ß√£o por estruturas eficazes
        if title.startswith('COMO'):
            score += 1.0
        if '?' in title:
            score += 0.5
        if title.count('|') > 0:
            score += 0.5

        return score

    def generate_titles_with_custom_prompt(self,
                                         source_titles: List[str],
                                         custom_prompt: str,
                                         count: int = 10,
                                         ai_provider: str = "auto") -> Dict:
        """Gerar t√≠tulos usando prompt personalizado"""
        results = {
            'generated_titles': [],
            'ai_provider_used': '',
            'patterns_analysis': {},
            'success': False,
            'error': None,
            'custom_prompt_used': custom_prompt
        }

        try:
            # Analisar padr√µes dos t√≠tulos originais
            results['patterns_analysis'] = self.analyze_viral_patterns(source_titles)

            # Criar prompt final combinando o personalizado com os t√≠tulos
            final_prompt = self.create_custom_prompt(source_titles, custom_prompt, count)

            # Tentar gerar com a IA escolhida
            if ai_provider == "openai" and self.openai_client:
                titles = self.generate_with_openai_custom(final_prompt)
                results['ai_provider_used'] = 'openai'
            elif ai_provider == "gemini" and self.gemini_model:
                titles = self.generate_with_gemini_custom(final_prompt)
                results['ai_provider_used'] = 'gemini'
            elif ai_provider == "openrouter" and self.openrouter_api_key:
                titles = self.generate_with_openrouter_custom(final_prompt, "anthropic/claude-3.5-sonnet")
                results['ai_provider_used'] = 'openrouter'
            else:
                # Modo autom√°tico - tentar OpenAI primeiro, depois OpenRouter, depois Gemini
                titles = []

                # Tentar OpenAI primeiro
                if self.openai_client:
                    try:
                        titles = self.generate_with_openai_custom(final_prompt)
                        results['ai_provider_used'] = 'openai'
                    except Exception as e:
                        print(f"‚ö†Ô∏è OpenAI falhou: {e}")

                # Tentar OpenRouter se OpenAI falhou
                if not titles and self.openrouter_api_key:
                    try:
                        titles = self.generate_with_openrouter_custom(final_prompt, "anthropic/claude-3.5-sonnet")
                        results['ai_provider_used'] = 'openrouter'
                    except Exception as e:
                        print(f"‚ö†Ô∏è OpenRouter falhou: {e}")

                # Tentar Gemini como √∫ltimo recurso
                if not titles and self.gemini_model:
                    try:
                        titles = self.generate_with_gemini_custom(final_prompt)
                        results['ai_provider_used'] = 'gemini'
                    except Exception as e:
                        print(f"‚ö†Ô∏è Gemini falhou: {e}")

                if not titles:
                    results['error'] = "Nenhuma IA conseguiu processar o prompt personalizado"
                    return results

            if titles:
                results['generated_titles'] = titles[:count]
                results['success'] = True
            else:
                results['error'] = "Nenhum t√≠tulo foi gerado"

            return results

        except Exception as e:
            results['error'] = str(e)
            return results

    def create_custom_prompt(self, source_titles: List[str], custom_prompt: str, count: int) -> str:
        """Criar prompt final combinando t√≠tulos originais com prompt personalizado"""
        prompt = f"""
T√çTULOS ORIGINAIS EXTRA√çDOS DO YOUTUBE:
{chr(10).join([f"‚Ä¢ {title}" for title in source_titles])}

INSTRU√á√ÉO PERSONALIZADA:
{custom_prompt}

TAREFA:
Com base nos t√≠tulos originais acima e seguindo a instru√ß√£o personalizada, crie {count} novos t√≠tulos √∫nicos e otimizados.

DIRETRIZES:
1. Use os t√≠tulos originais como inspira√ß√£o e refer√™ncia
2. Siga exatamente a instru√ß√£o personalizada fornecida
3. Mantenha a ess√™ncia viral dos t√≠tulos originais
4. Crie t√≠tulos √∫nicos e atraentes
5. Foque em gerar curiosidade e engajamento

FORMATO DE RESPOSTA:
Liste apenas os t√≠tulos numerados, um por linha:

1. [T√çTULO]
2. [T√çTULO]
...

Gere os {count} t√≠tulos agora:
"""
        return prompt

    def generate_with_openai_custom(self, prompt: str) -> List[str]:
        """Gerar t√≠tulos com OpenAI usando prompt personalizado"""
        if not self.openai_client:
            raise Exception("OpenAI n√£o configurado")

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube. Siga exatamente as instru√ß√µes fornecidas."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.8
            )

            content = response.choices[0].message.content
            titles = self.parse_generated_titles(content)

            return titles

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenAI: {e}")
            raise e

    def generate_with_gemini_custom(self, prompt: str) -> List[str]:
        """Gerar t√≠tulos com Gemini usando prompt personalizado"""
        if not self.gemini_model:
            raise Exception("Gemini n√£o configurado")

        try:
            print(f"üîç DEBUG: Enviando prompt personalizado para Gemini...")
            response = self.gemini_model.generate_content(prompt)
            print(f"üîç DEBUG: Resposta bruta do Gemini: {response.text[:300]}...")

            titles = self.parse_generated_titles(response.text)
            print(f"üîç DEBUG: T√≠tulos parseados do Gemini: {titles}")

            return titles

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o Gemini: {e}")
            raise e

    def generate_with_openrouter_custom(self, prompt: str, model: str = "anthropic/claude-3.5-sonnet") -> List[str]:
        """Gerar t√≠tulos com OpenRouter usando prompt personalizado"""
        if not self.openrouter_api_key:
            raise Exception("OpenRouter n√£o configurado")

        try:
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:5173",
                "X-Title": "Auto Video Producer"
            }

            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": "Voc√™ √© um especialista em cria√ß√£o de t√≠tulos virais para YouTube. Siga exatamente as instru√ß√µes fornecidas."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 1000,
                "temperature": 0.8
            }

            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                titles = self.parse_generated_titles(content)
                return titles
            else:
                raise Exception(f"OpenRouter API error: {response.status_code} - {response.text}")

        except Exception as e:
            print(f"‚ùå Erro na gera√ß√£o OpenRouter: {e}")
            raise e
